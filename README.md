# Self-Assessment 

The 24 weeks in this course tested my abilities as a data professional with many different concepts in each module. Each individual task presented in the modules was thorough and complex. Accompanied with detailed directions on how to apply the material in practical ways. Much of the challenge for me was the tempo of the program and the amount of information being presented. Focus and time management were huge factors to complete this program successfully. The results of all my efforts were well worth it when it was time to apply all the skills I learned in the final project. 




# Team Assessment

My teammates for the final project were Nicole and Luis. We teamed up out of pure admiration for each other's skills demonstrated during the boot camp. Nicole is an extremely talented and hard-working student and data professional. Her engagement in the classroom was the flag for me to approach her for the final project. Nicole's involvement in the project extended into the deployment of the database and organizational structure of the data, and this project wouldn't have been as accurate without her involvement. Luis is a great student with a great memory, he was one of the most active participants in this Bootcamp. His involvement in this project included practical approaches to implementing tools into the analysis. Overall id give my team an A+!




# Summary of Project  

The topic addressed in the final project was a box office revenue prediction using data from the TMDB dataset sourced from Kaggle. The dataset was intentionally messy and filled with tons of dense columns. The EDA and data cleaning were time intensive and extremely challenging. The Machine models were actually not as difficult once the data was cleaned and sorted. Machine models used were random forest, xgboost, and lightgbm. The results of the analysis were that Actors have more impact on revenue than budget, and Internet presence can generate 3 times more revenue, even with all the data provided in the data frame there was a 10% margin of error in the models, which translated into a mean revenue discrepancy of $41M-$43M.
